{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install collections"
      ],
      "metadata": {
        "id": "b43dCxcVPjF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHLf1fguPdB4",
        "outputId": "10021a11-27ea-460b-82ce-3e9aa39b260d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Starting Test 1 ===\n",
            "\n",
            "Test 1 Results:\n",
            "Total Correct: 14/20\n",
            "\n",
            "Topic Performance:\n",
            "Topic 1: 1/4 correct\n",
            "Topic 2: 4/4 correct\n",
            "Topic 3: 4/4 correct\n",
            "Topic 4: 2/4 correct\n",
            "Topic 5: 3/4 correct\n",
            "\n",
            "Upgraded Topics for Test 2: ['Topic 2', 'Topic 3']\n",
            "\n",
            "=== Starting Test 2 ===\n",
            "\n",
            "Test 2 Results:\n",
            "Total Correct: 15/20\n",
            "\n",
            "Topic Performance:\n",
            "Topic 1: 4/4 correct\n",
            "Topic 2: 4/4 correct\n",
            "Topic 3: 2/4 correct\n",
            "Topic 4: 3/4 correct\n",
            "Topic 5: 2/4 correct\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# Simulated Question Bank (60 questions)\n",
        "questions = [\n",
        "    {\n",
        "        \"id\": i,\n",
        "        \"topic\": f\"Topic {topic}\",\n",
        "        \"difficulty\": difficulty,\n",
        "        \"text\": f\"{difficulty} question {i//12 + 1} for Topic {topic}\"\n",
        "    }\n",
        "    for topic in range(1, 6)\n",
        "    for i, difficulty in enumerate(\n",
        "        [\"Easy\"]*4 + [\"Medium\"]*4 + [\"Hard\"]*4,\n",
        "        start=(topic-1)*12\n",
        "    )\n",
        "]\n",
        "\n",
        "class CATSystem:\n",
        "    def __init__(self):\n",
        "        self.user_performance = defaultdict(list)\n",
        "        self.current_test = 1\n",
        "\n",
        "    def run_test(self):\n",
        "        if self.current_test == 1:\n",
        "            test_questions = self._select_initial_questions()\n",
        "        else:\n",
        "            test_questions = self._select_adaptive_questions()\n",
        "\n",
        "        print(f\"\\n=== Starting Test {self.current_test} ===\")\n",
        "        results = self._simulate_test_taking(test_questions)\n",
        "        self._analyze_performance(results)\n",
        "\n",
        "        self.current_test += 1\n",
        "        return results\n",
        "\n",
        "    def _select_initial_questions(self):\n",
        "        \"\"\"Select 4 easy questions from each topic (20 total)\"\"\"\n",
        "        selected = []\n",
        "        for topic in range(1, 6):\n",
        "            topic_questions = [q for q in questions\n",
        "                             if q[\"topic\"] == f\"Topic {topic}\"\n",
        "                             and q[\"difficulty\"] == \"Easy\"][:4]\n",
        "            selected.extend(topic_questions)\n",
        "        return selected\n",
        "\n",
        "    def _select_adaptive_questions(self):\n",
        "        \"\"\"Select questions based on previous performance\"\"\"\n",
        "        selected = []\n",
        "        for topic in range(1, 6):\n",
        "            topic_perf = self.user_performance[f\"Topic {topic}\"]\n",
        "\n",
        "            # Get all questions from previous test in this topic\n",
        "            prev_questions = [q for q in self.user_performance[\"Test1\"]\n",
        "                            if q[\"question\"][\"topic\"] == f\"Topic {topic}\"]\n",
        "\n",
        "            # Check if all answers were correct\n",
        "            if all(res[\"correct\"] for res in prev_questions):\n",
        "                difficulty = \"Medium\"\n",
        "            else:\n",
        "                difficulty = \"Easy\"\n",
        "\n",
        "            # Select 4 questions of appropriate difficulty\n",
        "            topic_questions = [q for q in questions\n",
        "                             if q[\"topic\"] == f\"Topic {topic}\"\n",
        "                             and q[\"difficulty\"] == difficulty][:4]\n",
        "            selected.extend(topic_questions)\n",
        "        return selected\n",
        "\n",
        "    def _simulate_test_taking(self, test_questions):\n",
        "        \"\"\"Simulate user answering questions with random performance\"\"\"\n",
        "        results = []\n",
        "        for question in test_questions:\n",
        "            # Simulate user response (80% chance correct for demonstration)\n",
        "            is_correct = random.random() < 0.8  # Adjust this for different outcomes\n",
        "            time_spent = round(random.uniform(10, 60), 2)  # 10-60 seconds\n",
        "\n",
        "            result = {\n",
        "                \"question\": question,\n",
        "                \"correct\": is_correct,\n",
        "                \"time_spent\": time_spent,\n",
        "                \"attempts\": 1  # Simulating single attempt\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "            # Track performance per topic\n",
        "            self.user_performance[question[\"topic\"]].append(result)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _analyze_performance(self, results):\n",
        "        \"\"\"Analyze and display test results\"\"\"\n",
        "        correct = sum(1 for r in results if r[\"correct\"])\n",
        "        print(f\"\\nTest {self.current_test} Results:\")\n",
        "        print(f\"Total Correct: {correct}/{len(results)}\")\n",
        "\n",
        "        # Display topic-wise performance\n",
        "        topic_perf = defaultdict(list)\n",
        "        for res in results:\n",
        "            topic_perf[res[\"question\"][\"topic\"]].append(res[\"correct\"])\n",
        "\n",
        "        print(\"\\nTopic Performance:\")\n",
        "        for topic, scores in topic_perf.items():\n",
        "            correct = sum(scores)\n",
        "            print(f\"{topic}: {correct}/{len(scores)} correct\")\n",
        "\n",
        "    def get_upgraded_topics(self):\n",
        "        \"\"\"Get list of topics that will get harder questions\"\"\"\n",
        "        upgraded = []\n",
        "        for topic in range(1, 6):\n",
        "            prev_results = self.user_performance.get(f\"Topic {topic}\", [])\n",
        "            if prev_results and all(res[\"correct\"] for res in prev_results):\n",
        "                upgraded.append(f\"Topic {topic}\")\n",
        "        return upgraded\n",
        "\n",
        "# Simulation Usage\n",
        "if __name__ == \"__main__\":\n",
        "    cat = CATSystem()\n",
        "\n",
        "    # Take Test 1\n",
        "    test1_results = cat.run_test()\n",
        "\n",
        "    # Show which topics will be upgraded\n",
        "    upgraded_topics = cat.get_upgraded_topics()\n",
        "    print(\"\\nUpgraded Topics for Test 2:\", upgraded_topics or \"None\")\n",
        "\n",
        "    # Take Test 2\n",
        "    test2_results = cat.run_test()"
      ]
    }
  ]
}