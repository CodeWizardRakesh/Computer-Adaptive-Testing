{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install collections"
      ],
      "metadata": {
        "id": "b43dCxcVPjF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHLf1fguPdB4",
        "outputId": "06b53221-5205-4549-913c-41472b67f5cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Starting Test 1 ===\n",
            "\n",
            "Test Structure:\n",
            "Topic 1:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 2:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 3:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 4:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 5:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "\n",
            "Test 1 Results:\n",
            "Total Correct: 17/20\n",
            "\n",
            "Topic Performance:\n",
            "Topic 1: 4/4 correct\n",
            "Topic 2: 3/4 correct\n",
            "Topic 3: 3/4 correct\n",
            "Topic 4: 4/4 correct\n",
            "Topic 5: 3/4 correct\n",
            "\n",
            "Upgraded Topics for Test 2: ['Topic 1', 'Topic 4']\n",
            "\n",
            "=== Starting Test 2 ===\n",
            "\n",
            "Test Structure:\n",
            "Topic 1:\n",
            "  Easy: 0 questions\n",
            "  Medium: 4 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 2:\n",
            "  Easy: 0 questions\n",
            "  Medium: 4 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 3:\n",
            "  Easy: 0 questions\n",
            "  Medium: 4 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 4:\n",
            "  Easy: 0 questions\n",
            "  Medium: 4 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 5:\n",
            "  Easy: 0 questions\n",
            "  Medium: 4 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "\n",
            "Test 2 Results:\n",
            "Total Correct: 14/20\n",
            "\n",
            "Topic Performance:\n",
            "Topic 1: 1/4 correct\n",
            "Topic 2: 4/4 correct\n",
            "Topic 3: 3/4 correct\n",
            "Topic 4: 2/4 correct\n",
            "Topic 5: 4/4 correct\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# Simulated Question Bank (60 questions)\n",
        "questions = [\n",
        "    {\n",
        "        \"id\": i,\n",
        "        \"topic\": f\"Topic {topic}\",\n",
        "        \"difficulty\": difficulty,\n",
        "        \"text\": f\"{difficulty} question {i//12 + 1} for Topic {topic}\"\n",
        "    }\n",
        "    for topic in range(1, 6)\n",
        "    for i, difficulty in enumerate(\n",
        "        [\"Easy\"]*4 + [\"Medium\"]*4 + [\"Hard\"]*4,\n",
        "        start=(topic-1)*12\n",
        "    )\n",
        "]\n",
        "\n",
        "class CATSystem:\n",
        "    def __init__(self):\n",
        "        self.user_performance = defaultdict(list)\n",
        "        self.current_test = 1\n",
        "\n",
        "    def run_test(self):\n",
        "        if self.current_test == 1:\n",
        "            test_questions = self._select_initial_questions()\n",
        "        else:\n",
        "            test_questions = self._select_adaptive_questions()\n",
        "\n",
        "        print(f\"\\n=== Starting Test {self.current_test} ===\")\n",
        "        self._display_test_structure(test_questions)\n",
        "        results = self._simulate_test_taking(test_questions)\n",
        "        self._analyze_performance(results)\n",
        "\n",
        "        self.current_test += 1\n",
        "        return results\n",
        "\n",
        "    def _display_test_structure(self, test_questions):\n",
        "        \"\"\"Show difficulty distribution per topic\"\"\"\n",
        "        topic_stats = defaultdict(lambda: defaultdict(int))\n",
        "        for q in test_questions:\n",
        "            topic_stats[q['topic']][q['difficulty']] += 1\n",
        "\n",
        "        print(\"\\nTest Structure:\")\n",
        "        for topic in [f\"Topic {i}\" for i in range(1, 6)]:\n",
        "            stats = topic_stats[topic]\n",
        "            print(f\"{topic}:\")\n",
        "            print(f\"  Easy: {stats.get('Easy', 0)} questions\")\n",
        "            print(f\"  Medium: {stats.get('Medium', 0)} questions\")\n",
        "            print(f\"  Hard: {stats.get('Hard', 0)} questions\")\n",
        "            print()\n",
        "\n",
        "    def _select_initial_questions(self):\n",
        "        \"\"\"Select 4 easy questions from each topic (20 total)\"\"\"\n",
        "        selected = []\n",
        "        for topic in range(1, 6):\n",
        "            topic_questions = [q for q in questions\n",
        "                             if q[\"topic\"] == f\"Topic {topic}\"\n",
        "                             and q[\"difficulty\"] == \"Easy\"][:4]\n",
        "            selected.extend(topic_questions)\n",
        "        return selected\n",
        "\n",
        "    def _select_adaptive_questions(self):\n",
        "        \"\"\"Select questions based on previous performance\"\"\"\n",
        "        selected = []\n",
        "        for topic in range(1, 6):\n",
        "            topic_perf = self.user_performance[f\"Topic {topic}\"]\n",
        "\n",
        "            # Get all questions from previous test in this topic\n",
        "            prev_questions = [q for q in self.user_performance[\"Test1\"]\n",
        "                            if q[\"question\"][\"topic\"] == f\"Topic {topic}\"]\n",
        "\n",
        "            # Check if all answers were correct\n",
        "            if all(res[\"correct\"] for res in prev_questions):\n",
        "                difficulty = \"Medium\"\n",
        "            else:\n",
        "                difficulty = \"Easy\"\n",
        "\n",
        "            # Select 4 questions of appropriate difficulty\n",
        "            topic_questions = [q for q in questions\n",
        "                             if q[\"topic\"] == f\"Topic {topic}\"\n",
        "                             and q[\"difficulty\"] == difficulty][:4]\n",
        "            selected.extend(topic_questions)\n",
        "        return selected\n",
        "\n",
        "    def _simulate_test_taking(self, test_questions):\n",
        "        \"\"\"Simulate user answering questions with random performance\"\"\"\n",
        "        results = []\n",
        "        for question in test_questions:\n",
        "            # Simulate user response (80% chance correct for demonstration)\n",
        "            is_correct = random.random() < 0.8  # Adjust this for different outcomes\n",
        "            time_spent = round(random.uniform(10, 60), 2)  # 10-60 seconds\n",
        "\n",
        "            result = {\n",
        "                \"question\": question,\n",
        "                \"correct\": is_correct,\n",
        "                \"time_spent\": time_spent,\n",
        "                \"attempts\": 1  # Simulating single attempt\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "            # Track performance per topic\n",
        "            self.user_performance[question[\"topic\"]].append(result)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _analyze_performance(self, results):\n",
        "        \"\"\"Analyze and display test results\"\"\"\n",
        "        correct = sum(1 for r in results if r[\"correct\"])\n",
        "        print(f\"\\nTest {self.current_test} Results:\")\n",
        "        print(f\"Total Correct: {correct}/{len(results)}\")\n",
        "\n",
        "        # Display topic-wise performance\n",
        "        topic_perf = defaultdict(list)\n",
        "        for res in results:\n",
        "            topic_perf[res[\"question\"][\"topic\"]].append(res[\"correct\"])\n",
        "\n",
        "        print(\"\\nTopic Performance:\")\n",
        "        for topic, scores in topic_perf.items():\n",
        "            correct = sum(scores)\n",
        "            print(f\"{topic}: {correct}/{len(scores)} correct\")\n",
        "\n",
        "    def get_upgraded_topics(self):\n",
        "        \"\"\"Get list of topics that will get harder questions\"\"\"\n",
        "        upgraded = []\n",
        "        for topic in range(1, 6):\n",
        "            prev_results = self.user_performance.get(f\"Topic {topic}\", [])\n",
        "            if prev_results and all(res[\"correct\"] for res in prev_results):\n",
        "                upgraded.append(f\"Topic {topic}\")\n",
        "        return upgraded\n",
        "\n",
        "# Simulation Usage\n",
        "if __name__ == \"__main__\":\n",
        "    cat = CATSystem()\n",
        "\n",
        "    # Take Test 1\n",
        "    test1_results = cat.run_test()\n",
        "\n",
        "    # Show which topics will be upgraded\n",
        "    upgraded_topics = cat.get_upgraded_topics()\n",
        "    print(\"\\nUpgraded Topics for Test 2:\", upgraded_topics or \"None\")\n",
        "\n",
        "    # Take Test 2\n",
        "    test2_results = cat.run_test()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Simulated Question Bank (60 questions)\n",
        "questions = [\n",
        "    {\n",
        "        \"id\": i,\n",
        "        \"topic\": f\"Topic {topic}\",\n",
        "        \"difficulty\": difficulty,\n",
        "        \"text\": f\"{difficulty} question {i//12 + 1} for Topic {topic}\"\n",
        "    }\n",
        "    for topic in range(1, 6)\n",
        "    for i, difficulty in enumerate(\n",
        "        [\"Easy\"]*4 + [\"Medium\"]*4 + [\"Hard\"]*4,\n",
        "        start=(topic-1)*12\n",
        "    )\n",
        "]\n",
        "\n",
        "class CATSystem:\n",
        "    def __init__(self):\n",
        "        self.user_performance = defaultdict(list)\n",
        "        self.current_test = 1\n",
        "        self.model = DecisionTreeClassifier()  # Simple ML model\n",
        "\n",
        "    def run_test(self):\n",
        "        if self.current_test == 1:\n",
        "            test_questions = self._select_initial_questions()\n",
        "        else:\n",
        "            test_questions = self._select_adaptive_questions()\n",
        "\n",
        "        print(f\"\\n=== Starting Test {self.current_test} ===\")\n",
        "        self._display_test_structure(test_questions)\n",
        "        results = self._simulate_test_taking(test_questions)\n",
        "        self._analyze_performance(results)\n",
        "\n",
        "        # Train ML model after Test 1\n",
        "        if self.current_test == 1:\n",
        "            self._train_model()\n",
        "\n",
        "        self.current_test += 1\n",
        "        return results\n",
        "\n",
        "    def _display_test_structure(self, test_questions):\n",
        "        \"\"\"Show difficulty distribution per topic\"\"\"\n",
        "        topic_stats = defaultdict(lambda: defaultdict(int))\n",
        "        for q in test_questions:\n",
        "            topic_stats[q['topic']][q['difficulty']] += 1\n",
        "\n",
        "        print(\"\\nTest Structure:\")\n",
        "        for topic in [f\"Topic {i}\" for i in range(1, 6)]:\n",
        "            stats = topic_stats[topic]\n",
        "            print(f\"{topic}:\")\n",
        "            print(f\"  Easy: {stats.get('Easy', 0)} questions\")\n",
        "            print(f\"  Medium: {stats.get('Medium', 0)} questions\")\n",
        "            print(f\"  Hard: {stats.get('Hard', 0)} questions\")\n",
        "            print()\n",
        "\n",
        "    def _select_initial_questions(self):\n",
        "        \"\"\"Select 4 easy questions from each topic (20 total)\"\"\"\n",
        "        selected = []\n",
        "        for topic in range(1, 6):\n",
        "            topic_questions = [q for q in questions\n",
        "                             if q[\"topic\"] == f\"Topic {topic}\"\n",
        "                             and q[\"difficulty\"] == \"Easy\"][:4]\n",
        "            selected.extend(topic_questions)\n",
        "        return selected\n",
        "\n",
        "    def _select_adaptive_questions(self):\n",
        "        \"\"\"Select questions based on ML model predictions\"\"\"\n",
        "        selected = []\n",
        "        for topic in range(1, 6):\n",
        "            # Get topic performance features\n",
        "            avg_time, accuracy = self._calculate_topic_features(f\"Topic {topic}\")\n",
        "            predicted_difficulty = self.model.predict([[avg_time, accuracy]])[0]\n",
        "\n",
        "            # Select 4 questions of predicted difficulty\n",
        "            topic_questions = [q for q in questions\n",
        "                             if q[\"topic\"] == f\"Topic {topic}\"\n",
        "                             and q[\"difficulty\"] == predicted_difficulty][:4]\n",
        "            selected.extend(topic_questions)\n",
        "        return selected\n",
        "\n",
        "    def _simulate_test_taking(self, test_questions):\n",
        "        \"\"\"Simulate user answering questions with random performance\"\"\"\n",
        "        results = []\n",
        "        for question in test_questions:\n",
        "            # Simulate user response (80% chance correct for demonstration)\n",
        "            is_correct = random.random() < 0.8  # Adjust this for different outcomes\n",
        "            time_spent = round(random.uniform(10, 60), 2)  # 10-60 seconds\n",
        "\n",
        "            result = {\n",
        "                \"question\": question,\n",
        "                \"correct\": is_correct,\n",
        "                \"time_spent\": time_spent,\n",
        "                \"attempts\": 1  # Simulating single attempt\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "            # Track performance per topic\n",
        "            self.user_performance[question[\"topic\"]].append(result)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _analyze_performance(self, results):\n",
        "        \"\"\"Analyze and display test results\"\"\"\n",
        "        correct = sum(1 for r in results if r[\"correct\"])\n",
        "        print(f\"\\nTest {self.current_test} Results:\")\n",
        "        print(f\"Total Correct: {correct}/{len(results)}\")\n",
        "\n",
        "        # Display topic-wise performance\n",
        "        topic_perf = defaultdict(list)\n",
        "        for res in results:\n",
        "            topic_perf[res[\"question\"][\"topic\"]].append(res[\"correct\"])\n",
        "\n",
        "        print(\"\\nTopic Performance:\")\n",
        "        for topic, scores in topic_perf.items():\n",
        "            correct = sum(scores)\n",
        "            print(f\"{topic}: {correct}/{len(scores)} correct\")\n",
        "\n",
        "    def _train_model(self):\n",
        "        \"\"\"Train ML model on Test 1 data\"\"\"\n",
        "        X, y = [], []\n",
        "        for topic in range(1, 6):\n",
        "            avg_time, accuracy = self._calculate_topic_features(f\"Topic {topic}\")\n",
        "            X.append([avg_time, accuracy])\n",
        "            # Assign difficulty for the next test (e.g., Easy if low accuracy)\n",
        "            y.append(\"Easy\" if accuracy < 0.6 else \"Medium\")\n",
        "\n",
        "        self.model.fit(X, y)\n",
        "\n",
        "    def _calculate_topic_features(self, topic):\n",
        "        \"\"\"Calculate average time spent and accuracy for a topic\"\"\"\n",
        "        results = self.user_performance[topic]\n",
        "        if not results:\n",
        "            return 0, 0\n",
        "        avg_time = sum(r[\"time_spent\"] for r in results) / len(results)\n",
        "        accuracy = sum(r[\"correct\"] for r in results) / len(results)\n",
        "        return avg_time, accuracy\n",
        "\n",
        "# Simulation Usage\n",
        "if __name__ == \"__main__\":\n",
        "    cat = CATSystem()\n",
        "\n",
        "    # Take Test 1\n",
        "    test1_results = cat.run_test()\n",
        "\n",
        "    # Take Test 2\n",
        "    test2_results = cat.run_test()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMhiyzDhqze-",
        "outputId": "b3b132f4-8328-4a98-d687-97692fe869a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Starting Test 1 ===\n",
            "\n",
            "Test Structure:\n",
            "Topic 1:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 2:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 3:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 4:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 5:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "\n",
            "Test 1 Results:\n",
            "Total Correct: 15/20\n",
            "\n",
            "Topic Performance:\n",
            "Topic 1: 4/4 correct\n",
            "Topic 2: 3/4 correct\n",
            "Topic 3: 4/4 correct\n",
            "Topic 4: 1/4 correct\n",
            "Topic 5: 3/4 correct\n",
            "\n",
            "=== Starting Test 2 ===\n",
            "\n",
            "Test Structure:\n",
            "Topic 1:\n",
            "  Easy: 0 questions\n",
            "  Medium: 4 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 2:\n",
            "  Easy: 0 questions\n",
            "  Medium: 4 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 3:\n",
            "  Easy: 0 questions\n",
            "  Medium: 4 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 4:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 5:\n",
            "  Easy: 0 questions\n",
            "  Medium: 4 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "\n",
            "Test 2 Results:\n",
            "Total Correct: 16/20\n",
            "\n",
            "Topic Performance:\n",
            "Topic 1: 4/4 correct\n",
            "Topic 2: 3/4 correct\n",
            "Topic 3: 3/4 correct\n",
            "Topic 4: 3/4 correct\n",
            "Topic 5: 3/4 correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Simulated Question Bank (60 questions)\n",
        "questions = [\n",
        "    {\n",
        "        \"id\": i,\n",
        "        \"topic\": f\"Topic {topic}\",\n",
        "        \"difficulty\": difficulty,\n",
        "        \"text\": f\"{difficulty} question {i//12 + 1} for Topic {topic}\"\n",
        "    }\n",
        "    for topic in range(1, 6)\n",
        "    for i, difficulty in enumerate(\n",
        "        [\"Easy\"]*4 + [\"Medium\"]*4 + [\"Hard\"]*4,\n",
        "        start=(topic-1)*12\n",
        "    )\n",
        "]\n",
        "\n",
        "class CATSystem:\n",
        "    def __init__(self):\n",
        "        self.user_performance = defaultdict(list)\n",
        "        self.current_test = 1\n",
        "        self.model = DecisionTreeClassifier()  # Simple ML model\n",
        "\n",
        "    def run_test(self):\n",
        "        if self.current_test == 1:\n",
        "            test_questions = self._select_initial_questions()\n",
        "        else:\n",
        "            test_questions = self._select_adaptive_questions()\n",
        "\n",
        "        print(f\"\\n=== Starting Test {self.current_test} ===\")\n",
        "        self._display_test_structure(test_questions)\n",
        "        results = self._simulate_test_taking(test_questions)\n",
        "        self._analyze_performance(results)\n",
        "\n",
        "        # Train ML model after Test 1\n",
        "        if self.current_test == 1:\n",
        "            self._train_model()\n",
        "\n",
        "        self.current_test += 1\n",
        "        return results\n",
        "\n",
        "    def _display_test_structure(self, test_questions):\n",
        "        \"\"\"Show difficulty distribution per topic\"\"\"\n",
        "        topic_stats = defaultdict(lambda: defaultdict(int))\n",
        "        for q in test_questions:\n",
        "            topic_stats[q['topic']][q['difficulty']] += 1\n",
        "\n",
        "        print(\"\\nTest Structure:\")\n",
        "        for topic in [f\"Topic {i}\" for i in range(1, 6)]:\n",
        "            stats = topic_stats[topic]\n",
        "            print(f\"{topic}:\")\n",
        "            print(f\"  Easy: {stats.get('Easy', 0)} questions\")\n",
        "            print(f\"  Medium: {stats.get('Medium', 0)} questions\")\n",
        "            print(f\"  Hard: {stats.get('Hard', 0)} questions\")\n",
        "            print()\n",
        "\n",
        "    def _select_initial_questions(self):\n",
        "        \"\"\"Select 4 easy questions from each topic (20 total)\"\"\"\n",
        "        selected = []\n",
        "        for topic in range(1, 6):\n",
        "            topic_questions = [q for q in questions\n",
        "                             if q[\"topic\"] == f\"Topic {topic}\"\n",
        "                             and q[\"difficulty\"] == \"Easy\"][:4]\n",
        "            selected.extend(topic_questions)\n",
        "        return selected\n",
        "\n",
        "    def _select_adaptive_questions(self):\n",
        "        \"\"\"Select questions based on ML model predictions\"\"\"\n",
        "        selected = []\n",
        "        for topic in range(1, 6):\n",
        "            # Get topic performance features\n",
        "            avg_time, accuracy, avg_attempts = self._calculate_topic_features(f\"Topic {topic}\")\n",
        "            predicted_difficulty = self.model.predict([[avg_time, accuracy, avg_attempts]])[0]\n",
        "\n",
        "            # Select 4 questions of predicted difficulty\n",
        "            topic_questions = [q for q in questions\n",
        "                             if q[\"topic\"] == f\"Topic {topic}\"\n",
        "                             and q[\"difficulty\"] == predicted_difficulty][:4]\n",
        "            selected.extend(topic_questions)\n",
        "        return selected\n",
        "\n",
        "    def _simulate_test_taking(self, test_questions):\n",
        "        \"\"\"Simulate user answering questions with random performance\"\"\"\n",
        "        results = []\n",
        "        for question in test_questions:\n",
        "            # Simulate user response (80% chance correct for demonstration)\n",
        "            is_correct = random.random() < 0.8  # Adjust this for different outcomes\n",
        "            time_spent = round(random.uniform(10, 60), 2)  # 10-60 seconds\n",
        "            attempts = random.randint(1, 3)  # Simulating up to 3 attempts\n",
        "\n",
        "            result = {\n",
        "                \"question\": question,\n",
        "                \"correct\": is_correct,\n",
        "                \"time_spent\": time_spent,\n",
        "                \"attempts\": attempts\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "            # Track performance per topic\n",
        "            self.user_performance[question[\"topic\"]].append(result)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _analyze_performance(self, results):\n",
        "        \"\"\"Analyze and display test results\"\"\"\n",
        "        correct = sum(1 for r in results if r[\"correct\"])\n",
        "        print(f\"\\nTest {self.current_test} Results:\")\n",
        "        print(f\"Total Correct: {correct}/{len(results)}\")\n",
        "\n",
        "        # Display topic-wise performance\n",
        "        topic_perf = defaultdict(list)\n",
        "        for res in results:\n",
        "            topic_perf[res[\"question\"][\"topic\"]].append(res[\"correct\"])\n",
        "\n",
        "        print(\"\\nTopic Performance:\")\n",
        "        for topic, scores in topic_perf.items():\n",
        "            correct = sum(scores)\n",
        "            print(f\"{topic}: {correct}/{len(scores)} correct\")\n",
        "\n",
        "    def _train_model(self):\n",
        "        \"\"\"Train ML model on Test 1 data\"\"\"\n",
        "        X, y = [], []\n",
        "        for topic in range(1, 6):\n",
        "            avg_time, accuracy, avg_attempts = self._calculate_topic_features(f\"Topic {topic}\")\n",
        "            X.append([avg_time, accuracy, avg_attempts])\n",
        "            # Assign difficulty for the next test (e.g., Easy if low accuracy)\n",
        "            y.append(\"Easy\" if accuracy < 0.6 else \"Medium\")\n",
        "\n",
        "        self.model.fit(X, y)\n",
        "\n",
        "    def _calculate_topic_features(self, topic):\n",
        "        \"\"\"Calculate average time spent, accuracy, and attempts for a topic\"\"\"\n",
        "        results = self.user_performance[topic]\n",
        "        if not results:\n",
        "            return 0, 0, 0\n",
        "        avg_time = sum(r[\"time_spent\"] for r in results) / len(results)\n",
        "        accuracy = sum(r[\"correct\"] for r in results) / len(results)\n",
        "        avg_attempts = sum(r[\"attempts\"] for r in results) / len(results)\n",
        "        return avg_time, accuracy, avg_attempts\n",
        "\n",
        "# Simulation Usage\n",
        "if __name__ == \"__main__\":\n",
        "    cat = CATSystem()\n",
        "\n",
        "    # Take Test 1\n",
        "    test1_results = cat.run_test()\n",
        "\n",
        "    # Take Test 2\n",
        "    test2_results = cat.run_test()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vfim7srq0hf",
        "outputId": "13ec69ff-19e8-40c0-8815-da90b9a387d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Starting Test 1 ===\n",
            "\n",
            "Test Structure:\n",
            "Topic 1:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 2:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 3:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 4:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 5:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "\n",
            "Test 1 Results:\n",
            "Total Correct: 16/20\n",
            "\n",
            "Topic Performance:\n",
            "Topic 1: 3/4 correct\n",
            "Topic 2: 4/4 correct\n",
            "Topic 3: 2/4 correct\n",
            "Topic 4: 3/4 correct\n",
            "Topic 5: 4/4 correct\n",
            "\n",
            "=== Starting Test 2 ===\n",
            "\n",
            "Test Structure:\n",
            "Topic 1:\n",
            "  Easy: 0 questions\n",
            "  Medium: 4 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 2:\n",
            "  Easy: 0 questions\n",
            "  Medium: 4 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 3:\n",
            "  Easy: 4 questions\n",
            "  Medium: 0 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 4:\n",
            "  Easy: 0 questions\n",
            "  Medium: 4 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "Topic 5:\n",
            "  Easy: 0 questions\n",
            "  Medium: 4 questions\n",
            "  Hard: 0 questions\n",
            "\n",
            "\n",
            "Test 2 Results:\n",
            "Total Correct: 19/20\n",
            "\n",
            "Topic Performance:\n",
            "Topic 1: 4/4 correct\n",
            "Topic 2: 4/4 correct\n",
            "Topic 3: 3/4 correct\n",
            "Topic 4: 4/4 correct\n",
            "Topic 5: 4/4 correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Simulated Question Bank (60 questions)\n",
        "questions = [\n",
        "    {\n",
        "        \"id\": i,\n",
        "        \"topic\": f\"Topic {topic}\",\n",
        "        \"difficulty\": difficulty,\n",
        "        \"difficulty_score\": {\"Easy\": 0, \"Medium\": 1, \"Hard\": 2}[difficulty],\n",
        "        \"text\": f\"{difficulty} question {i//12 + 1} for Topic {topic}\"\n",
        "    }\n",
        "    for topic in range(1, 6)\n",
        "    for i, difficulty in enumerate(\n",
        "        [\"Easy\"]*4 + [\"Medium\"]*4 + [\"Hard\"]*4,\n",
        "        start=(topic-1)*12\n",
        "    )\n",
        "]\n",
        "\n",
        "class CATSystem:\n",
        "    def __init__(self):\n",
        "        self.user_performance = defaultdict(list)\n",
        "        self.current_test = 1\n",
        "        self.models = {}  # ML model per topic\n",
        "        self.scalers = {} # Scaler per topic\n",
        "\n",
        "        # Initialize synthetic training data for demonstration\n",
        "        self._initialize_ml_models()\n",
        "\n",
        "    def _initialize_ml_models(self):\n",
        "        \"\"\"Create pre-trained models with synthetic data\"\"\"\n",
        "        for topic in range(1, 6):\n",
        "            # Synthetic training data: [avg_time, accuracy] -> can_handle_higher_difficulty\n",
        "            X = np.array([\n",
        "                [20, 1.0],  # Fast + perfect\n",
        "                [50, 0.8],  # Medium speed + good\n",
        "                [60, 0.5],  # Slow + mediocre\n",
        "                [45, 0.6],\n",
        "                [30, 0.9]\n",
        "            ])\n",
        "            y = np.array([1, 1, 0, 0, 1])  # 1 = can handle harder questions\n",
        "\n",
        "            self.scalers[topic] = StandardScaler().fit(X)\n",
        "            X_scaled = self.scalers[topic].transform(X)\n",
        "\n",
        "            self.models[topic] = LogisticRegression()\n",
        "            self.models[topic].fit(X_scaled, y)\n",
        "\n",
        "    def _calculate_topic_features(self, topic):\n",
        "        \"\"\"Extract features for ML model: [avg_time, accuracy]\"\"\"\n",
        "        topic_results = self.user_performance.get(topic, [])\n",
        "        if not topic_results:\n",
        "            return None\n",
        "\n",
        "        total_time = sum(r['time_spent'] for r in topic_results)\n",
        "        avg_time = total_time / len(topic_results)\n",
        "        accuracy = sum(r['correct'] for r in topic_results) / len(topic_results)\n",
        "\n",
        "        return np.array([[avg_time, accuracy]])\n",
        "\n",
        "    def _display_test_structure(self, test_questions):\n",
        "        \"\"\"Show difficulty distribution per topic\"\"\"\n",
        "        difficulty_counts = defaultdict(int)\n",
        "        for q in test_questions:\n",
        "          difficulty_counts[q['difficulty']] += 1\n",
        "\n",
        "        print(\"\\nTest Structure:\")\n",
        "        for difficulty, count in difficulty_counts.items():\n",
        "          print(f\"{difficulty}: {count} questions\")\n",
        "\n",
        "    def _predict_difficulty(self, topic, features):\n",
        "        \"\"\"Predict if user can handle higher difficulty\"\"\"\n",
        "        scaled_features = self.scalers[topic].transform(features)\n",
        "        prob = self.models[topic].predict_proba(scaled_features)[0][1]\n",
        "        return prob > 0.65  # Threshold for difficulty increase\n",
        "\n",
        "    def run_test(self):\n",
        "        test_questions = self._select_questions()\n",
        "\n",
        "        print(f\"\\n=== Starting Test {self.current_test} ===\")\n",
        "        self._display_test_structure(test_questions)\n",
        "        results = self._simulate_test_taking(test_questions)\n",
        "        self._analyze_performance(results)\n",
        "\n",
        "        self.current_test += 1\n",
        "        return results\n",
        "\n",
        "    def _analyze_performance(self, results):\n",
        "        correct_counts = defaultdict(int)\n",
        "        difficulty_counts = defaultdict(int)\n",
        "\n",
        "        for res in results:\n",
        "            difficulty_counts[res[\"question\"][\"difficulty\"]] += 1\n",
        "            if res[\"correct\"]:\n",
        "                correct_counts[res[\"question\"][\"difficulty\"]] += 1\n",
        "\n",
        "        print(\"\\nPerformance by Difficulty Level:\")\n",
        "        for difficulty in [\"Easy\", \"Medium\", \"Hard\"]:\n",
        "            total = difficulty_counts[difficulty]\n",
        "            correct = correct_counts[difficulty]\n",
        "            print(f\"{difficulty}: {correct}/{total} correct\")\n",
        "\n",
        "        total_correct = sum(correct_counts.values())\n",
        "        print(f\"\\nOverall: {total_correct}/{len(results)} correct\")\n",
        "\n",
        "    def _select_questions(self):\n",
        "        \"\"\"Select questions based on current test number and ML predictions\"\"\"\n",
        "        if self.current_test == 1:\n",
        "            return self._select_initial_questions()\n",
        "\n",
        "        selected = []\n",
        "        for topic in range(1, 6):\n",
        "            # Get ML features for the topic\n",
        "            features = self._calculate_topic_features(f\"Topic {topic}\")\n",
        "            if features is None:\n",
        "                difficulty = \"Easy\"\n",
        "            else:\n",
        "                # Predict if user can handle higher difficulty\n",
        "                topic_num = topic\n",
        "                should_upgrade = self._predict_difficulty(topic_num, features)\n",
        "                difficulty = \"Medium\" if should_upgrade else \"Easy\"\n",
        "\n",
        "            # Select questions\n",
        "            topic_questions = [q for q in questions\n",
        "                             if q[\"topic\"] == f\"Topic {topic}\"\n",
        "                             and q[\"difficulty\"] == difficulty][:4]\n",
        "            selected.extend(topic_questions)\n",
        "        return selected\n",
        "\n",
        "    def _select_initial_questions(self):\n",
        "        \"\"\"Select 4 easy questions from each topic (20 total)\"\"\"\n",
        "        return [q for q in questions if q[\"difficulty\"] == \"Easy\"][:20]\n",
        "\n",
        "    # ... (keep other methods like _display_test_structure,\n",
        "    # _simulate_test_taking, _analyze_performance from previous version)\n",
        "\n",
        "    def _simulate_test_taking(self, test_questions):\n",
        "        \"\"\"Simulate user answering questions with time-based performance\"\"\"\n",
        "        results = []\n",
        "        for question in test_questions:\n",
        "            # Base correct probability based on difficulty\n",
        "            base_prob = {\n",
        "                \"Easy\": 0.85,\n",
        "                \"Medium\": 0.65,\n",
        "                \"Hard\": 0.4\n",
        "            }[question[\"difficulty\"]]\n",
        "\n",
        "            # Time effect: faster answers more likely to be correct\n",
        "            time_spent = random.uniform(15, 60)\n",
        "            time_factor = np.interp(time_spent, [15, 60], [1.2, 0.8])\n",
        "            is_correct = random.random() < base_prob * time_factor\n",
        "\n",
        "            result = {\n",
        "                \"question\": question,\n",
        "                \"correct\": is_correct,\n",
        "                \"time_spent\": round(time_spent, 2),\n",
        "                \"attempts\": 1\n",
        "            }\n",
        "            results.append(result)\n",
        "            self.user_performance[question[\"topic\"]].append(result)\n",
        "\n",
        "        return results\n",
        "\n",
        "# Simulation Usage\n",
        "if __name__ == \"__main__\":\n",
        "    cat = CATSystem()\n",
        "\n",
        "    # Take Test 1\n",
        "    test1_results = cat.run_test()\n",
        "\n",
        "    # Take Test 2 with ML-based recommendations\n",
        "    test2_results = cat.run_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-_JHx1S1_9h",
        "outputId": "0f241f7a-bb7e-4f25-a815-66e0c8a8390f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Starting Test 1 ===\n",
            "\n",
            "Test Structure:\n",
            "Easy: 20 questions\n",
            "\n",
            "Performance by Difficulty Level:\n",
            "Easy: 17/20 correct\n",
            "Medium: 0/0 correct\n",
            "Hard: 0/0 correct\n",
            "\n",
            "Overall: 17/20 correct\n",
            "\n",
            "=== Starting Test 2 ===\n",
            "\n",
            "Test Structure:\n",
            "Easy: 8 questions\n",
            "Medium: 12 questions\n",
            "\n",
            "Performance by Difficulty Level:\n",
            "Easy: 6/8 correct\n",
            "Medium: 10/12 correct\n",
            "Hard: 0/0 correct\n",
            "\n",
            "Overall: 16/20 correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Generation**"
      ],
      "metadata": {
        "id": "3TK8GbuQV8So"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(42)\n",
        "n_samples = 1000  # Number of data points\n",
        "\n",
        "data = {\n",
        "    \"question_id\": np.arange(1, n_samples + 1),\n",
        "    \"time_spent\": np.random.normal(30, 10, n_samples).clip(5, 60),  # Time in seconds\n",
        "    \"difficulty\": np.random.choice([\"Easy\", \"Medium\", \"Hard\"], n_samples, p=[0.3, 0.5, 0.2]),\n",
        "    \"attempts\": np.random.randint(1, 5, n_samples),\n",
        "    \"avg_time_spent\": np.random.normal(30, 5, n_samples).clip(10, 50),\n",
        "    \"is_correct\": np.random.choice([0, 1], n_samples, p=[0.4, 0.6]),  # 60% correct answers\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(\"cat_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "sdX9gE9BCvi3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"cat_dataset.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xJcBjdNIWSXI",
        "outputId": "2b6dd3aa-5808-45cf-bc83-3c8e30b620fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   question_id  time_spent difficulty  attempts  avg_time_spent  is_correct\n",
              "0            1   34.967142       Easy         2       30.948531           1\n",
              "1            2   28.617357       Easy         4       26.690089           1\n",
              "2            3   36.476885     Medium         3       32.129436           0\n",
              "3            4   45.230299     Medium         4       30.095739           1\n",
              "4            5   27.658466       Easy         4       26.792565           1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7039907-bf4e-4a22-9fbf-11c8275ccab3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>time_spent</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>attempts</th>\n",
              "      <th>avg_time_spent</th>\n",
              "      <th>is_correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>34.967142</td>\n",
              "      <td>Easy</td>\n",
              "      <td>2</td>\n",
              "      <td>30.948531</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>28.617357</td>\n",
              "      <td>Easy</td>\n",
              "      <td>4</td>\n",
              "      <td>26.690089</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>36.476885</td>\n",
              "      <td>Medium</td>\n",
              "      <td>3</td>\n",
              "      <td>32.129436</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>45.230299</td>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>30.095739</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>27.658466</td>\n",
              "      <td>Easy</td>\n",
              "      <td>4</td>\n",
              "      <td>26.792565</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7039907-bf4e-4a22-9fbf-11c8275ccab3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7039907-bf4e-4a22-9fbf-11c8275ccab3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7039907-bf4e-4a22-9fbf-11c8275ccab3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e41545e6-768f-436b-907a-428d325153c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e41545e6-768f-436b-907a-428d325153c5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e41545e6-768f-436b-907a-428d325153c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"question_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288,\n        \"min\": 1,\n        \"max\": 1000,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          522,\n          738,\n          741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_spent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.72546799087258,\n        \"min\": 5.0,\n        \"max\": 60.0,\n        \"num_unique_values\": 996,\n        \"samples\": [\n          45.50500492814077,\n          25.538165667852205,\n          32.96120277064576\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"difficulty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Easy\",\n          \"Medium\",\n          \"Hard\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attempts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_time_spent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.9347682639773085,\n        \"min\": 15.044320145496384,\n        \"max\": 49.63118853218163,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          19.49986746174188,\n          27.722302369880648,\n          34.38023396264897\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_correct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Preprocessing*"
      ],
      "metadata": {
        "id": "dIUBA_fYWhCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"cat_dataset.csv\")\n",
        "\n",
        "# Encode difficulty labels\n",
        "le = LabelEncoder()\n",
        "df[\"difficulty\"] = le.fit_transform(df[\"difficulty\"])  # Easy=0, Medium=1, Hard=2\n",
        "\n",
        "# Features and target\n",
        "X = df[[\"time_spent\", \"attempts\", \"avg_time_spent\", \"is_correct\"]]\n",
        "y = df[\"difficulty\"]\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features (optional, based on model)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "HWKG5HOwWXIc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "_hz3IkHfWw1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train a classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b81cRFNfWxrE",
        "outputId": "58165605-6fa2-4a8f-ae4e-2dad3bf38e3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.415\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Easy       0.38      0.19      0.26        62\n",
            "        Hard       0.24      0.20      0.22        40\n",
            "      Medium       0.47      0.64      0.54        98\n",
            "\n",
            "    accuracy                           0.41       200\n",
            "   macro avg       0.36      0.35      0.34       200\n",
            "weighted avg       0.39      0.41      0.39       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Gen**"
      ],
      "metadata": {
        "id": "Mlf18uSSalV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(42)\n",
        "n_users = 500  # Number of users\n",
        "topics = [1, 2, 3, 4, 5]\n",
        "difficulties = [\"Easy\", \"Medium\", \"Hard\"]\n",
        "\n",
        "data = []\n",
        "for user in range(n_users):\n",
        "    for topic in topics:\n",
        "        # Randomly assign current difficulty\n",
        "        current_diff = np.random.choice(difficulties, p=[0.3, 0.4, 0.3])\n",
        "\n",
        "        # Simulate performance metrics\n",
        "        avg_time = np.random.normal(loc=30 if current_diff == \"Easy\" else 45 if current_diff == \"Medium\" else 60, scale=10)\n",
        "        avg_attempts = np.random.randint(1, 4) if current_diff == \"Easy\" else np.random.randint(2, 5)\n",
        "        success_rate = np.clip(np.random.normal(loc=0.7 if current_diff == \"Easy\" else 0.5 if current_diff == \"Medium\" else 0.3, scale=0.15), 0, 1)\n",
        "\n",
        "        # Define next difficulty based on rules (simulate ground truth)\n",
        "        if success_rate > 0.75:\n",
        "            next_diff = \"Hard\" if current_diff == \"Medium\" else \"Medium\" if current_diff == \"Easy\" else \"Hard\"\n",
        "        elif success_rate < 0.4:\n",
        "            next_diff = \"Easy\" if current_diff == \"Medium\" else \"Medium\" if current_diff == \"Hard\" else \"Easy\"\n",
        "        else:\n",
        "            next_diff = current_diff\n",
        "\n",
        "        data.append([\n",
        "            user, topic, current_diff,\n",
        "            np.abs(avg_time), avg_attempts, success_rate, next_diff\n",
        "        ])\n",
        "\n",
        "df = pd.DataFrame(data, columns=[\"user_id\", \"topic\", \"current_difficulty\",\n",
        "                                  \"avg_time_spent\", \"avg_attempts\", \"success_rate\",\n",
        "                                  \"next_difficulty\"])\n",
        "df.to_csv(\"adaptive_test_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "L2v_sGo3an3g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "_FyNxXyRaoqy",
        "outputId": "9820e097-f564-4589-b751-d1da5329a548"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      user_id  topic current_difficulty  avg_time_spent  avg_attempts  \\\n",
              "0           0      1             Medium       33.881199             4   \n",
              "1           0      2               Easy        9.890371             3   \n",
              "2           0      3               Easy       24.191219             1   \n",
              "3           0      4             Medium       45.222218             4   \n",
              "4           0      5               Easy       20.919759             2   \n",
              "...       ...    ...                ...             ...           ...   \n",
              "2495      499      1               Easy       24.678561             2   \n",
              "2496      499      2             Medium       61.765979             3   \n",
              "2497      499      3               Easy       40.270459             1   \n",
              "2498      499      4             Medium       63.420001             4   \n",
              "2499      499      5               Easy       10.866677             1   \n",
              "\n",
              "      success_rate next_difficulty  \n",
              "0         0.547835          Medium  \n",
              "1         0.626079            Easy  \n",
              "2         0.621225            Easy  \n",
              "3         0.435831          Medium  \n",
              "4         0.488154            Easy  \n",
              "...            ...             ...  \n",
              "2495      0.641715            Easy  \n",
              "2496      0.509648          Medium  \n",
              "2497      0.605377            Easy  \n",
              "2498      0.516709          Medium  \n",
              "2499      0.792985          Medium  \n",
              "\n",
              "[2500 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f4e8adf-a4dc-4e3d-a1ba-dc732195a1db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>topic</th>\n",
              "      <th>current_difficulty</th>\n",
              "      <th>avg_time_spent</th>\n",
              "      <th>avg_attempts</th>\n",
              "      <th>success_rate</th>\n",
              "      <th>next_difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Medium</td>\n",
              "      <td>33.881199</td>\n",
              "      <td>4</td>\n",
              "      <td>0.547835</td>\n",
              "      <td>Medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Easy</td>\n",
              "      <td>9.890371</td>\n",
              "      <td>3</td>\n",
              "      <td>0.626079</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Easy</td>\n",
              "      <td>24.191219</td>\n",
              "      <td>1</td>\n",
              "      <td>0.621225</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Medium</td>\n",
              "      <td>45.222218</td>\n",
              "      <td>4</td>\n",
              "      <td>0.435831</td>\n",
              "      <td>Medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>Easy</td>\n",
              "      <td>20.919759</td>\n",
              "      <td>2</td>\n",
              "      <td>0.488154</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2495</th>\n",
              "      <td>499</td>\n",
              "      <td>1</td>\n",
              "      <td>Easy</td>\n",
              "      <td>24.678561</td>\n",
              "      <td>2</td>\n",
              "      <td>0.641715</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>499</td>\n",
              "      <td>2</td>\n",
              "      <td>Medium</td>\n",
              "      <td>61.765979</td>\n",
              "      <td>3</td>\n",
              "      <td>0.509648</td>\n",
              "      <td>Medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>499</td>\n",
              "      <td>3</td>\n",
              "      <td>Easy</td>\n",
              "      <td>40.270459</td>\n",
              "      <td>1</td>\n",
              "      <td>0.605377</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>499</td>\n",
              "      <td>4</td>\n",
              "      <td>Medium</td>\n",
              "      <td>63.420001</td>\n",
              "      <td>4</td>\n",
              "      <td>0.516709</td>\n",
              "      <td>Medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>499</td>\n",
              "      <td>5</td>\n",
              "      <td>Easy</td>\n",
              "      <td>10.866677</td>\n",
              "      <td>1</td>\n",
              "      <td>0.792985</td>\n",
              "      <td>Medium</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2500 rows  7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f4e8adf-a4dc-4e3d-a1ba-dc732195a1db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f4e8adf-a4dc-4e3d-a1ba-dc732195a1db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f4e8adf-a4dc-4e3d-a1ba-dc732195a1db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f75d9eb9-c69d-486b-80be-501887fec8ac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f75d9eb9-c69d-486b-80be-501887fec8ac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f75d9eb9-c69d-486b-80be-501887fec8ac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8b278a7a-196e-4a2a-86b6-74e3deb187d2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8b278a7a-196e-4a2a-86b6-74e3deb187d2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2500,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 144,\n        \"min\": 0,\n        \"max\": 499,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          361,\n          73,\n          374\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"current_difficulty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Medium\",\n          \"Easy\",\n          \"Hard\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_time_spent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.998148376726302,\n        \"min\": 3.9578614337286595,\n        \"max\": 90.76860370180503,\n        \"num_unique_values\": 2500,\n        \"samples\": [\n          66.4955326373281,\n          55.673988934432344,\n          55.36191494391911\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_attempts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"success_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2103264304258886,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2476,\n        \"samples\": [\n          0.26426494874165735,\n          0.45362418147970407,\n          0.8436898082823525\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"next_difficulty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Medium\",\n          \"Easy\",\n          \"Hard\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "hRcp0wxjbBRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"adaptive_test_dataset.csv\")\n",
        "\n",
        "# Encode categorical features\n",
        "le_diff = LabelEncoder()\n",
        "le_topic = LabelEncoder()\n",
        "\n",
        "df[\"current_difficulty\"] = le_diff.fit_transform(df[\"current_difficulty\"])\n",
        "df[\"topic\"] = le_topic.fit_transform(df[\"topic\"])\n",
        "df[\"next_difficulty\"] = le_diff.transform(df[\"next_difficulty\"])\n",
        "\n",
        "# Features and target\n",
        "X = df[[\"topic\", \"current_difficulty\", \"avg_time_spent\", \"avg_attempts\", \"success_rate\"]]\n",
        "y = df[\"next_difficulty\"]\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "fwW4d7mrazfY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "ZJQIPTUIbFuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize and train the model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "print(classification_report(y_test, y_pred, target_names=le_diff.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQthrQbQbEoN",
        "outputId": "51b004f9-45a3-475d-b425-0ad9376c61af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Easy       1.00      1.00      1.00       138\n",
            "        Hard       1.00      1.00      1.00        54\n",
            "      Medium       1.00      1.00      1.00       308\n",
            "\n",
            "    accuracy                           1.00       500\n",
            "   macro avg       1.00      1.00      1.00       500\n",
            "weighted avg       1.00      1.00      1.00       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Difficulty Suggestion"
      ],
      "metadata": {
        "id": "kw-v9FDZbJ86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save artifacts\n",
        "joblib.dump(model, \"difficulty_predictor.pkl\")\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "joblib.dump(le_diff, \"label_encoder.pkl\")\n",
        "\n",
        "# Load artifacts\n",
        "model = joblib.load(\"difficulty_predictor.pkl\")\n",
        "scaler = joblib.load(\"scaler.pkl\")\n",
        "le_diff = joblib.load(\"label_encoder.pkl\")\n",
        "\n",
        "def suggest_difficulty(topic, current_diff, avg_time, avg_attempts, success_rate):\n",
        "    # Encode inputs\n",
        "    topic_encoded = le_topic.transform([topic])[0]\n",
        "    current_diff_encoded = le_diff.transform([current_diff])[0]\n",
        "\n",
        "    # Prepare features\n",
        "    features = np.array([[topic_encoded, current_diff_encoded, avg_time, avg_attempts, success_rate]])\n",
        "    features_scaled = scaler.transform(features)\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(features_scaled)\n",
        "    return le_diff.inverse_transform(pred)[0]\n",
        "\n",
        "# Example usage\n",
        "print(suggest_difficulty(\n",
        "    topic=2,\n",
        "    current_diff=\"Easy\",\n",
        "    avg_time=45,\n",
        "    avg_attempts=3,\n",
        "    success_rate=0.8\n",
        "))  # Output: \"Hard\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rQFMAAJbL_J",
        "outputId": "a46e5315-bbd3-41a2-a923-889a2a5f4d5e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Medium\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CGFPh8qPbNMy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}